{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arnav/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/mnt/Arnav/Coding/Projects/mime/'\n",
    "TEST_DIR = '/mnt/Arnav/Coding/Projects/mime/train-set'\n",
    "LR = 1e-3\n",
    "MODEL_NAME = 'gesture-{}-{}.model'.format(LR, 'hack-ph-v3')\n",
    "IMG_SIZE = 50\n",
    "language = 'en'\n",
    "display = 0\n",
    "prev_na = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(image):\n",
    "    image = image.replace('/', '.')\n",
    "    label = image.split('.')[-3]\n",
    "    if (label == 'a'):\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    elif (label == 'b'):\n",
    "        return [0, 1, 0, 0, 0, 0, 0]\n",
    "    elif (label == 'stop'):\n",
    "        return [0, 0, 1, 0, 0, 0, 0]\n",
    "    elif (label == 'blank'):\n",
    "        return [0, 0, 0, 1, 0, 0, 0]\n",
    "    elif (label == 'v'):\n",
    "        return [0, 0, 0, 0, 1, 0, 0]\n",
    "    elif (label == 'ok'):\n",
    "        return [0, 0, 0, 0, 0, 1, 0]\n",
    "    elif (label == 'hello'):\n",
    "        return [0, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data(path):\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        if (img == \"raw_data.txt\" or img == \"train_data.npy\"):\n",
    "            continue\n",
    "        label = get_label(img)\n",
    "        image = cv2.cvtColor(cv2.imread(path+'/'+img), cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "        # print(image)\n",
    "        training_data.append([np.array(image), np.array(label)])\n",
    "    # print(training_data)\n",
    "    shuffle(training_data)\n",
    "    np.save(path + '/train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arnav/anaconda3/lib/python3.7/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /home/arnav/anaconda3/lib/python3.7/site-packages/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/arnav/anaconda3/lib/python3.7/site-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/arnav/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, [5, 5], activation='relu')\n",
    "convnet = max_pool_2d(convnet, [2, 2])\n",
    "\n",
    "convnet = conv_2d(convnet, 64, [5, 5], activation='relu')\n",
    "convnet = max_pool_2d(convnet, [2, 2])\n",
    "\n",
    "convnet = conv_2d(convnet, 128, [5, 5], activation='relu')\n",
    "convnet = max_pool_2d(convnet, [2, 2])\n",
    "\n",
    "convnet = conv_2d(convnet, 64, [5, 5], activation='relu')\n",
    "convnet = max_pool_2d(convnet, [2, 2])\n",
    "\n",
    "convnet = conv_2d(convnet, 32, [5, 5], activation='relu')\n",
    "convnet = max_pool_2d(convnet, [2, 2])\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 7, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "##################################\n",
    "### Uncomment if Training Data ###\n",
    "##################################\n",
    "\n",
    "# train_data = create_train_data('/mnt/Arnav/Coding/Projects/project-gesture/gestures/train-set-ph')\n",
    "    \n",
    "# train = train_data[:-50]\n",
    "# test = train_data[-50:]\n",
    "\n",
    "# X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "# Y = [i[1] for i in train]\n",
    "\n",
    "# test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "# test_y = [i[1] for i in test]\n",
    "\n",
    "# model.fit({'input': X}, {'targets': Y}, n_epoch=5, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "#     snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "# model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/arnav/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /mnt/Arnav/Coding/Projects/project-gesture/final-notebooks/final-ph-v3/gesture-0.001-hack-ph-v3.model\n"
     ]
    }
   ],
   "source": [
    "model.load(TRAIN_DIR + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrediction(prediction):\n",
    "    cv2.putText(frame, 'A', (5, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,10),(35+int(prediction[0][0]*100),10),(0,255,0),5)\n",
    "    cv2.putText(frame, 'B', (5, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,25),(35+int(prediction[0][1]*100),25),(0,255,0),5)\n",
    "    cv2.putText(frame, 'stop', (5, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,40),(35+int(prediction[0][2]*100),40),(0,255,0),5)\n",
    "    cv2.putText(frame, 'N/A', (5, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,55),(35+int(prediction[0][3]*100),55),(0,255,0),5)\n",
    "    cv2.putText(frame, 'V', (5, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,70),(35+int(prediction[0][4]*100),70),(0,255,0),5)\n",
    "    cv2.putText(frame, 'ok', (5, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,85),(35+int(prediction[0][5]*100),85),(0,255,0),5)\n",
    "    cv2.putText(frame, 'hi', (5, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.line(frame,(35,100),(35+int(prediction[0][6]*100),100),(0,255,0),5)\n",
    "    \n",
    "#     cv2.putText(frame, 'NA', (5, 105), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "#     cv2.line(frame,(35,100),(35+int(prediction[0][4]*100),100),(0,255,0),5)\n",
    "#     print(int(prediction[0][0]*100))\n",
    "#     print(type(int(prediction[0][0])))\n",
    "\n",
    "def getPrediction():\n",
    "    model_out = model.predict([data])\n",
    "    plotPrediction(model_out)\n",
    "    # cv2.putText(frame,str(model_out),(50,200), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "#     if(model_out[0][5] >= 0.3):\n",
    "#         return 'N/A'\n",
    "    if np.argmax(model_out) == 0:\n",
    "        return 'A'\n",
    "        # cv2.putText(frame,'A',(50,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    elif np.argmax(model_out) == 1:\n",
    "        return 'B'\n",
    "        #cv2.putText(frame,'B',(50,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    elif np.argmax(model_out) == 2:\n",
    "        return 'stop'\n",
    "        # cv2.putText(frame,'C',(50,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    elif np.argmax(model_out) == 3:\n",
    "        return 'N/A'\n",
    "        #cv2.putText(frame,'F',(50,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    elif np.argmax(model_out) == 4:\n",
    "        return 'V'\n",
    "        #cv2.putText(frame,'N/A',(50,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    elif np.argmax(model_out) == 5:\n",
    "        return 'OK'\n",
    "    elif np.argmax(model_out) == 6:\n",
    "        return 'HELLO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "xi = 300\n",
    "yi = 100\n",
    "extra = 250\n",
    "counter = 0\n",
    "prev_na = 0\n",
    "prev_op = output = ''\n",
    "\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "## Capturing Video using Smartphone Camera\n",
    "url='http://192.168.43.227:8080/video'\n",
    "\n",
    "cap = cv2.VideoCapture(url)\n",
    "while(True):\n",
    "    _, frame = cap.read()\n",
    "    height, width = frame.shape[:2]\n",
    "    frame = cv2.resize(frame, (int(width/2), int(height/2)))\n",
    "    blurred = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    blue_low = np.array([100, 50, 50])\n",
    "    blue_up = np.array([130, 255, 255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, blue_low, blue_up)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if (area > 3000):\n",
    "            cv2.drawContours(frame, contour, -1, (0, 255, 0), 3)\n",
    "            if (counter < 500 and cv2.waitKey(1) == ord('c')):\n",
    "                #### Press 'c' to capture image for data collection\n",
    "                # print(counter)\n",
    "                path = '/mnt/Arnav/Coding/Projects/project-gesture/gestures/hello-ph/hello.' + str(counter) + '.jpg'\n",
    "#                 path2 = '/mnt/Arnav/Coding/Projects/project-gesture/gestures/imageres' + str(counter) + '.jpg'\n",
    "#                 path3 = '/mnt/Arnav/Coding/Projects/project-gesture/gestures/imageframe' + str(counter) + '.jpg'\n",
    "                cv2.imwrite(path, mask[yi:yi+extra, xi:xi+extra])\n",
    "#                 cv2.imwrite(path2, res[yi:yi+extra, xi:xi+extra])\n",
    "#                 cv2.imwrite(path3, frame[yi:yi+extra, xi:xi+extra])\n",
    "                counter=counter+1;\n",
    "#             (x,y,w,h) = cv2.boundingRect(contour)\n",
    "#             cv2.rectangle(frame, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "#             cv2.rectangle(mask, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "#             cv2.rectangle(res, (x,y), (x+w,y+h), (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    cv2.rectangle(frame, (xi,yi), (xi+extra,yi+extra), (0, 255, 0), 2)\n",
    "    # cv2.rectangle(mask, (xi,yi), (xi+extra,yi+extra), (0, 255, 0), 2)\n",
    "    cv2.rectangle(res, (xi,yi), (xi+extra,yi+extra), (0, 255, 0), 2)\n",
    "    \n",
    "    roi = mask[yi:yi+extra, xi:xi+extra]\n",
    "    # roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    roi = cv2.resize(roi, (IMG_SIZE, IMG_SIZE))\n",
    "    data = roi.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    \n",
    "    ans = getPrediction()\n",
    "    prev_op = ans\n",
    "    if(ans == 'stop' and prev_op != 'N/A' and prev_op != 'stop'):\n",
    "        prev_na = 1\n",
    "        output += prev_op\n",
    "    cv2.putText(frame,output,(50,300), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "#     if (cv2.waitKey(1) == ord('p')):\n",
    "#         print('ans: ' + output)\n",
    "#         cv2.putText(frame,output,(100,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "#         output = ''\n",
    "    cv2.putText(frame,ans,(50,200), cv2.FONT_HERSHEY_SIMPLEX, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "    # frame = cv2.flip(frame, 1);\n",
    "    cv2.putText(frame,'stored: ' +  str(counter) ,(10,450), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('res', res)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
